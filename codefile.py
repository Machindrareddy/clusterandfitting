# -*- coding: utf-8 -*-
"""AH31465.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eVGee9JCNkXwP9qGNFZ-ieaySRMohLyc
"""

# Import the pandas library and alias it as pd
import pandas as pd

# Specify the file path of the CSV file
file_path = "C:\\Users\\kurva\\Downloads\\FUNDAMENTALS OF DATA SCIENCE\\API_19_DS2_en_csv_v2_6300757.csv"

# Read the CSV file into a pandas DataFrame
# - sep=',': Specifies that the values in the CSV file are separated by commas
# - skiprows=4: Skips the first 4 rows of the CSV file while reading
df = pd.read_csv(file_path, sep='\t')

df

# Filter rows in the DataFrame where 'Indicator Code' is equal to 'EN.ATM.CO2E.PC'
CO2_per_capita = df[df['Indicator Code'] == 'EN.ATM.CO2E.PC']

# Set the index of the DataFrame to 'Country Code'
CO2_per_capita.set_index('Country Code', inplace=True)

# Drop columns 'Indicator Code', 'Indicator Name', and 'Country Name' from the DataFrame
CO2_per_capita.drop(['Indicator Code', 'Indicator Name', 'Country Name'], axis=1, inplace=True)

# Transpose the DataFrame to swap rows and columns
CO2_per_capita = CO2_per_capita.T

# Display the resulting DataFrame
CO2_per_capita
# Filter rows in the DataFrame where 'Indicator Code' is equal to 'EN.ATM.CO2E.PC'
CO2_per_capita = df[df['Indicator Code'] == 'EN.ATM.CO2E.PC']

# Set the index of the DataFrame to 'Country Code'
CO2_per_capita.set_index('Country Code', inplace=True)

# Drop columns 'Indicator Code', 'Indicator Name', and 'Country Name' from the DataFrame
CO2_per_capita.drop(['Indicator Code', 'Indicator Name', 'Country Name'], axis=1, inplace=True)

# Transpose the DataFrame to swap rows and columns
CO2_per_capita = CO2_per_capita.T

# Display the resulting DataFrame
CO2_per_capita

CO2_per_capita.shape

CO2_per_capita.isna().sum()

# Import the matplotlib.pyplot library and alias it as plt
import matplotlib.pyplot as plt

# Plot the CO2 per capita data for the country with code 'AGO' (Angola)
CO2_per_capita['AGO'].plot()

# Display the plot
plt.show()

# Select rows in the DataFrame from the year '1990' to '2020'
CO2_per_capita_1990_2020 = CO2_per_capita.loc['1990': '2020']

# Display the resulting DataFrame containing CO2 per capita data for the years 1990 to 2020
CO2_per_capita_1990_2020

Country_code=CO2_per_capita_1990_2020.columns.values

# Check for NaN (missing) values in the DataFrame CO2_per_capita_1990_2020 and sum them for each country
nadata = CO2_per_capita_1990_2020.isna().sum().reset_index()

# Rename the columns of the resulting DataFrame to 'Country' and 'NaN Count'
nadata.columns = ['Country', 'NaN Count']

# Display the resulting DataFrame containing the count of NaN values for each country
nadata

# Transpose the DataFrame CO2_per_capita_1990_2020, swapping rows and columns
CO2_per_capita_1990_2020_T = CO2_per_capita_1990_2020.T

CO2_per_capita_1990_2020_T["NaN Count"] = nadata["NaN Count"].values

CO2_per_capita_1990_2020_T

CO2_per_capita_1990_2020_T=CO2_per_capita_1990_2020_T[CO2_per_capita_1990_2020_T["NaN Count"] != 31].drop(columns=["NaN Count"])

CO2_per_capita_1990_2020_T = CO2_per_capita_1990_2020_T.fillna(0)
CO2_per_capita_1990_2020_T

def scaler(df):
    """ Expects a dataframe and normalises all
        columnsto the 0-1 range. It also returns
        dataframes with minimum and maximum for
        transforming the cluster centres"""

    # Uses the pandas methods
    df_min = df.min()
    df_max = df.max()

    df = (df-df_min) / (df_max - df_min)

    return df, df_min, df_max

CO2_per_capita_1990_2020_T_norm,CO2_per_capita_1990_2020_T_min,CO2_per_capita_1990_2020_T_max = scaler(CO2_per_capita_1990_2020_T)
CO2_per_capita_1990_2020_T_norm

CO2_per_capita_1990_2020_T_min

CO2_per_capita_1990_2020_T_max

# Import the KMeans algorithm from scikit-learn
from sklearn.cluster import KMeans

# Create an empty list to store the within-cluster sum of squares (WCSS) for different numbers of clusters
wcss = []

# Iterate over a range of cluster numbers from 1 to 10
for i in range(1, 11):
    # Create a KMeans model with the current number of clusters
    kmeans = KMeans(n_clusters=i, random_state=0)

    # Fit the KMeans model to the normalized transposed data (CO2_per_capita_1990_2020_T_norm)
    kmeans.fit(CO2_per_capita_1990_2020_T_norm)

    # Append the WCSS (inertia) to the list
    wcss.append(kmeans.inertia_)
legend  = ["Elbow graph"]
# Plot the Elbow Method graph to find the optimal number of clusters
plt.plot(range(1, 11), wcss,)
plt.legend(legend)
plt.title('The Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')

plt.show()

kmeans = KMeans(n_clusters=3, random_state=0)
kmeans.fit(CO2_per_capita_1990_2020_T_norm)
labels = kmeans.labels_
cluster_centers = kmeans.cluster_centers_
cluster_centers = pd.DataFrame(cluster_centers).T
cluster_centers

from matplotlib import pyplot as plt
cluster_centers.plot(kind='line', figsize=(8, 4), title=0)
plt.gca().spines[['top', 'right']].set_visible(False)
plt.title('cluster centers')
plt.xlabel('Year')
plt.ylabel('EN.ATM.CO2E.PC')

CO2_per_capita_1990_2020_T["labels"]=labels
CO2_per_capita_1990_2020_T

CO2_per_capita_1990_2020_T['labels'].value_counts()

# Select rows from the transposed DataFrame where 'labels' column is equal to 0,
# sample 5 rows, and drop the 'labels' column
cl0 = CO2_per_capita_1990_2020_T[CO2_per_capita_1990_2020_T['labels'] == 0].sample(n=5).drop(columns=["labels"])

# Transpose the resulting DataFrame
cl0 = cl0.T

# Plot the data for Cluster 0
cl0.plot()

# Set the title, xlabel, and ylabel for the plot
plt.title('Cluster 0')
plt.xlabel('Year')
plt.ylabel('EN.ATM.CO2E.PC')

# Display the plot
plt.show()

cl1=CO2_per_capita_1990_2020_T[CO2_per_capita_1990_2020_T['labels'] == 1].sample(n=5).drop(columns=["labels"])
cl1 = cl1.T
cl1.plot()
plt.title('Cluster 1')
plt.xlabel('year')
plt.ylabel('EN.ATM.CO2E.PC')
plt.show()

cl2=CO2_per_capita_1990_2020_T[CO2_per_capita_1990_2020_T['labels'] == 2].sample(n=5).drop(columns=["labels"])
cl2 = cl2.T
cl2.plot()
plt.title('Cluster 2')
plt.xlabel('year')
plt.ylabel('EN.ATM.CO2E.PC')
plt.show()

def subset(Indicator_Code):
    """
    Extracts a subset of data for a specific indicator code.

    Parameters:
    - Indicator_Code (str): Indicator code for the desired subset.

    Returns:
    - DataFrame: Subset of data for the specified indicator code.
    """

    # Filter rows in the DataFrame where 'Indicator Code' is equal to the provided code
    data = df[df['Indicator Code'] == Indicator_Code]

    # Set the index of the DataFrame to 'Country Code'
    data.set_index('Country Code', inplace=True)

    # Drop columns 'Indicator Code', 'Indicator Name', and 'Country Name' from the DataFrame
    data.drop(['Indicator Code', 'Indicator Name', 'Country Name'], axis=1, inplace=True)

    # Transpose the DataFrame to swap rows and columns
    data = data.T

    # Select rows in the transposed DataFrame from the year '1990' to '2020'
    data = data.loc['1990': '2020']

    return data

Indicator_Code = "EN.ATM.CO2E.PP.GD"
CO2_emissions_GDP = subset(Indicator_Code)
CO2_emissions_GDP

CO2_emissions_GDP = CO2_emissions_GDP.fillna(0)
CO2_emissions_GDP['Total'] = CO2_emissions_GDP.sum(axis=1)
CO2_emissions_GDP['Total']

CO2_emissions_GDP['Total'].plot()
plt.title('Cluster 2')
plt.xlabel('year')
plt.ylabel('EN.ATM.CO2E.PC')
plt.show()

# Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.seasonal import seasonal_decompose

# Decompose the time series into trend, seasonal, and residual components
result = seasonal_decompose(CO2_emissions_GDP['Total'], model='additive', period=2)
# Adjust 'your_seasonality' based on the seasonality in your data

# Plot the original time series and its components
plt.figure(figsize=(12, 8))

# Plot the original time series
plt.subplot(4, 1, 1)
plt.plot(CO2_emissions_GDP['Total'], label='Original Time Series')
plt.legend()

# Plot the trend component
plt.subplot(4, 1, 2)
plt.plot(result.trend, label='Trend')
plt.legend()

# Plot the seasonal component
plt.subplot(4, 1, 3)
plt.plot(result.seasonal, label='Seasonality')
plt.legend()

# Plot the residual component
plt.subplot(4, 1, 4)
plt.plot(result.resid, label='Residuals')
plt.legend()

# Adjust the layout for better visualization
plt.tight_layout()

# Display the plots
plt.show()

# prompt: create a column name total save the coresponding sum as the value.
CO2_emissions_GDP_T= CO2_emissions_GDP.drop(columns=('Total')).T
CO2_emissions_GDP_T['Total'] = CO2_emissions_GDP_T.sum(axis=1)
CO2_emissions_GDP_T=CO2_emissions_GDP_T[CO2_emissions_GDP_T['Total'] != 0]

CO2_emissions_GDP_T_norm,CO2_emissions_GDP_T_min,CO2_emissions_GDP_T_max = scaler(CO2_emissions_GDP_T)
CO2_emissions_GDP_T_norm

wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, random_state=0)
    kmeans.fit(CO2_emissions_GDP_T_norm)
    wcss.append(kmeans.inertia_)
plt.plot(range(1, 11), wcss)
plt.title('The Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

kmeans = KMeans(n_clusters=2, random_state=100)
kmeans.fit(CO2_emissions_GDP_T_norm.drop(columns=["Total"]))
labels = kmeans.labels_
cluster_centers = kmeans.cluster_centers_
cluster_centers

from matplotlib import pyplot as plt
cluster_centers.plot(kind='line', figsize=(8, 4), title=0)
plt.gca().spines[['top', 'right']].set_visible(False)

CO2_emissions_GDP_T["labels"]=labels
CO2_emissions_GDP_T

CO2_emissions_GDP_T['labels'].value_counts()

cl0=CO2_emissions_GDP_T[CO2_emissions_GDP_T['labels'] == 0].sample(n=5).drop(columns=["labels","Total"])
cl0 = cl0.T
cl0.plot()

plt.title('Cluster 0')
plt.xlabel('year')
plt.ylabel(Indicator_Code)
plt.show()

cl1=CO2_emissions_GDP_T[CO2_emissions_GDP_T['labels'] == 1].sample(n=5).drop(columns=["labels","Total"])
cl1 = cl1.T
cl1.plot()
plt.title('Cluster 1')
plt.xlabel('year')
plt.ylabel(Indicator_Code)
plt.show()

CO2_per_capita_1990_2020_T

CO2_per_capita_1990_2020_T['Total'] = CO2_per_capita_1990_2020_T.sum(axis=1)
a=CO2_per_capita_1990_2020_T['Total']

b=CO2_emissions_GDP_T['Total']

data = pd.merge(a, b, left_index=True, right_index=True, how='inner')

data.columns=['CO2_per_capita', 'CO2_emissions_GDP']

data.plot.scatter(x='CO2_per_capita', y='CO2_emissions_GDP')

from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(data[['CO2_per_capita']], data[['CO2_emissions_GDP']])
# Make predictions
y_pred = regressor.predict(data[['CO2_per_capita']])

# Evaluate the model
r2_score = regressor.score(data[['CO2_per_capita']], data[['CO2_emissions_GDP']])
print('R-squared:', r2_score)

print('The equation of the model is: CO2_per_capita = ', regressor.coef_[0], '*CO2_emissions_GDP +', regressor.intercept_)

data.plot.scatter(x='CO2_per_capita', y='CO2_emissions_GDP')
plt.plot(data[['CO2_per_capita']], y_pred, color='red')
plt.legend(["Data","Linear Regression Line"])